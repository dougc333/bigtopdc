# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
Source: oozie
Section: misc
Priority: extra
Maintainer: Bigtop <bigtop-dev@incubator.apache.org>
Build-Depends: debhelper (>= 6)
Depends: zip, unzip
Standards-Version: 3.8.0
Homepage: http://incubator.apache.org/oozie/

Package: oozie-client
Architecture: all
Depends: bigtop-utils
Description: Command line utility that allows
 remote access and operation of oozie. Using this utility, the
 user can deploy workflows and perform other administrative and
 monitoring tasks such as start, stop, kill, resume workflows
 and coordinator jobs.

Package: oozie
Architecture: all
Depends: oozie-client (= ${source:Version}), hadoop, zip, unzip
Description: A workflow and coordinator sytem for Hadoop jobs.
 Oozie workflows are actions arranged in a control dependency DAG (Direct
 Acyclic Graph).
 .
 Oozie coordinator functionality allows to start workflows at regular
 frequencies and when data becomes available in HDFS.
 .
 An Oozie workflow may contain the following types of actions nodes:
 map-reduce, map-reduce streaming, map-reduce pipes, pig, file-system,
 sub-workflows, java, hive, sqoop and ssh (deprecated).
 .
 Flow control operations within the workflow can be done using decision,
 fork and join nodes. Cycles in workflows are not supported.
 .
 Actions and decisions can be parameterized with job properties, actions
 output (i.e. Hadoop counters) and HDFS  file information (file exists,
 file size, etc). Formal parameters are expressed in the workflow definition
 as ${VAR} variables.
 .
 A Workflow application is an HDFS directory that contains the workflow
 definition (an XML file), all the necessary files to run all the actions:
 JAR files for Map/Reduce jobs, shells for streaming Map/Reduce jobs, native
 libraries, Pig scripts, and other resource files.
 .
 Running workflow jobs is done via command line tools, a WebServices API or
 a Java API.
 .
 Monitoring the system and workflow jobs can be done via a web console, the
 command line tools, the WebServices API and the Java API.
 .
 Oozie is a transactional system and it has built in automatic and manual
 retry capabilities.
 .
 In case of workflow job failure, the workflow job can be rerun skipping
 previously completed actions, the workflow application can be patched before
 being rerun.

