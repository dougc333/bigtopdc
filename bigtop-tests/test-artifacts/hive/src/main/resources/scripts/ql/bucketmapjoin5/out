-- Licensed to the Apache Software Foundation (ASF) under one or more
-- contributor license agreements.  See the NOTICE file distributed with
-- this work for additional information regarding copyright ownership.
-- The ASF licenses this file to You under the Apache License, Version 2.0
-- (the "License") you may not use this file except in compliance with
-- the License.  You may obtain a copy of the License at
--
--     http://www.apache.org/licenses/LICENSE-2.0
--
-- Unless required by applicable law or agreed to in writing, software
-- distributed under the License is distributed on an "AS IS" BASIS,
-- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-- See the License for the specific language governing permissions and
-- limitations under the License.
CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE

load data local inpath 'seed_data_files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket20.txt

load data local inpath 'seed_data_files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket21.txt


CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE

load data local inpath 'seed_data_files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket20.txt

load data local inpath 'seed_data_files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket21.txt

load data local inpath 'seed_data_files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket22.txt

load data local inpath 'seed_data_files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket23.txt

load data local inpath 'seed_data_files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-09')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket20.txt

load data local inpath 'seed_data_files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-09')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket21.txt

load data local inpath 'seed_data_files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-09')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket22.txt

load data local inpath 'seed_data_files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-09')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket23.txt


CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE

load data local inpath 'seed_data_files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket22.txt

load data local inpath 'seed_data_files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket23.txt

load data local inpath 'seed_data_files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-09')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket22.txt

load data local inpath 'seed_data_files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-09')
Copying file: file:/var/lib/hudson/workspace/Nightly-smoke-testing-monster/examples/hive/target/seed_data_files/srcbucket23.txt


create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint)

create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint)
set hive.optimize.bucketmapjoin = true

create table bucketmapjoin_tmp_result (key string , value1 string, value2 string)


explain extended
insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
on a.key=b.key
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME srcbucket_mapjoin) a) (TOK_TABREF (TOK_TABNAME srcbucket_mapjoin_part) b) (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME bucketmapjoin_tmp_result))) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) value)))))

STAGE DEPENDENCIES:
  Stage-7 is a root stage
  Stage-1 depends on stages: Stage-7
  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
  Stage-4
  Stage-0 depends on stages: Stage-4, Stage-3
  Stage-2 depends on stages: Stage-0
  Stage-3

STAGE PLANS:
  Stage: Stage-7
    Map Reduce Local Work
      Alias -> Map Local Tables:
        a 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            HashTable Sink Operator
              condition expressions:
                0 {key} {value}
                1 {value}
              handleSkewJoin: false
              keys:
                0 [Column[key]]
                1 [Column[key]]
              Position of Big Table: 1
      Bucket Mapjoin Context:
          Alias Bucket Base File Name Mapping:
            a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket20.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket21.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket22.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket23.txt=[srcbucket21.txt]}
          Alias Bucket File Name Mapping:
            a {hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket20.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket21.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket20.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket21.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket20.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket21.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket20.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
          Alias Bucket Output File Name Mapping:
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt 0
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt 1
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt 2
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt 3

  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            GatherStats: false
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              condition expressions:
                0 {key} {value}
                1 {value}
              handleSkewJoin: false
              keys:
                0 [Column[key]]
                1 [Column[key]]
              outputColumnNames: _col0, _col1, _col5
              Position of Big Table: 1
              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: string
                      expr: _col5
                      type: string
                outputColumnNames: _col0, _col1, _col5
                Select Operator
                  expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: string
                        expr: _col5
                        type: string
                  outputColumnNames: _col0, _col1, _col2
                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    directory: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10002
                    NumFilesPerFileSink: 1
                    Stats Publishing Key Prefix: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10000/
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          bucket_count -1
                          columns key,value1,value2
                          columns.types string:string:string
                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
                          name default.bucketmapjoin_tmp_result
                          serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          transient_lastDdlTime 1301691359
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: default.bucketmapjoin_tmp_result
                    TotalFiles: 1
                    GatherStats: true
                    MultiFileSpray: false
      Local Work:
        Map Reduce Local Work
      Needs Tagging: false
      Path -> Alias:
        hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
        hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 [b]
      Path -> Partition:
        hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
          Partition
            base file name: ds=2008-04-08
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
            properties:
              bucket_count 4
              bucket_field_name key
              columns key,value
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-08
              name default.srcbucket_mapjoin_part
              partition_columns ds
              serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1301691354
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 4
                bucket_field_name key
                columns key,value
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part
                name default.srcbucket_mapjoin_part
                partition_columns ds
                serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1301691354
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcbucket_mapjoin_part
            name: default.srcbucket_mapjoin_part
        hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 
          Partition
            base file name: ds=2008-04-09
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-09
            properties:
              bucket_count 4
              bucket_field_name key
              columns key,value
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part/ds=2008-04-09
              name default.srcbucket_mapjoin_part
              partition_columns ds
              serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1301691354
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 4
                bucket_field_name key
                columns key,value
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part
                name default.srcbucket_mapjoin_part
                partition_columns ds
                serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1301691354
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcbucket_mapjoin_part
            name: default.srcbucket_mapjoin_part

  Stage: Stage-5
    Conditional Operator

  Stage: Stage-4
    Move Operator
      files:
          hdfs directory: true
          source: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10002
          destination: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10000

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10000
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
                name default.bucketmapjoin_tmp_result
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1301691359
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.bucketmapjoin_tmp_result
          tmp directory: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10001

  Stage: Stage-2
    Stats-Aggr Operator
      Stats Aggregation Key Prefix: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10000/

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10002 
            File Output Operator
              compressed: false
              GlobalTableId: 0
              directory: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10000
              NumFilesPerFileSink: 1
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    columns key,value1,value2
                    columns.types string:string:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
                    name default.bucketmapjoin_tmp_result
                    serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    transient_lastDdlTime 1301691359
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: default.bucketmapjoin_tmp_result
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false
      Needs Tagging: false
      Path -> Alias:
        hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10002 [hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10002]
      Path -> Partition:
        hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-55-59_802_8749339940103211895/-ext-10002 
          Partition
            base file name: -ext-10002
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value1,value2
              columns.types string:string:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
              name default.bucketmapjoin_tmp_result
              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1301691359
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
                name default.bucketmapjoin_tmp_result
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1301691359
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.bucketmapjoin_tmp_result
            name: default.bucketmapjoin_tmp_result




insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
on a.key=b.key
Deleted hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result


select count(1) from bucketmapjoin_tmp_result
928

insert overwrite table bucketmapjoin_hash_result_1
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
Deleted hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_hash_result_1
set hive.optimize.bucketmapjoin = false

insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
on a.key=b.key
Deleted hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result


select count(1) from bucketmapjoin_tmp_result
928

insert overwrite table bucketmapjoin_hash_result_2
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
Deleted hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_hash_result_2


select a.key-b.key, a.value1-b.value1, a.value2-b.value2
from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
on a.key = b.key
0	0	0
set hive.optimize.bucketmapjoin = true

explain extended
insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part_2 b 
on a.key=b.key
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME srcbucket_mapjoin) a) (TOK_TABREF (TOK_TABNAME srcbucket_mapjoin_part_2) b) (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB (TOK_TABNAME bucketmapjoin_tmp_result))) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) value)))))

STAGE DEPENDENCIES:
  Stage-7 is a root stage
  Stage-1 depends on stages: Stage-7
  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
  Stage-4
  Stage-0 depends on stages: Stage-4, Stage-3
  Stage-2 depends on stages: Stage-0
  Stage-3

STAGE PLANS:
  Stage: Stage-7
    Map Reduce Local Work
      Alias -> Map Local Tables:
        a 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            HashTable Sink Operator
              condition expressions:
                0 {key} {value}
                1 {value}
              handleSkewJoin: false
              keys:
                0 [Column[key]]
                1 [Column[key]]
              Position of Big Table: 1
      Bucket Mapjoin Context:
          Alias Bucket Base File Name Mapping:
            a {srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket22.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket23.txt=[srcbucket21.txt]}
          Alias Bucket File Name Mapping:
            a {hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket20.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket21.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket20.txt], hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt=[hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
          Alias Bucket Output File Name Mapping:
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt 0
            hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt 1

  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            GatherStats: false
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              condition expressions:
                0 {key} {value}
                1 {value}
              handleSkewJoin: false
              keys:
                0 [Column[key]]
                1 [Column[key]]
              outputColumnNames: _col0, _col1, _col5
              Position of Big Table: 1
              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: string
                      expr: _col5
                      type: string
                outputColumnNames: _col0, _col1, _col5
                Select Operator
                  expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: string
                        expr: _col5
                        type: string
                  outputColumnNames: _col0, _col1, _col2
                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    directory: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10002
                    NumFilesPerFileSink: 1
                    Stats Publishing Key Prefix: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10000/
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          bucket_count -1
                          columns key,value1,value2
                          columns.types string:string:string
                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
                          name default.bucketmapjoin_tmp_result
                          numFiles 1
                          numPartitions 0
                          numRows 0
                          serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          totalSize 17966
                          transient_lastDdlTime 1301691422
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: default.bucketmapjoin_tmp_result
                    TotalFiles: 1
                    GatherStats: true
                    MultiFileSpray: false
      Local Work:
        Map Reduce Local Work
      Needs Tagging: false
      Path -> Alias:
        hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
        hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]
      Path -> Partition:
        hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
          Partition
            base file name: ds=2008-04-08
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
            properties:
              bucket_count 2
              bucket_field_name key
              columns key,value
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08
              name default.srcbucket_mapjoin_part_2
              partition_columns ds
              serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1301691357
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 2
                bucket_field_name key
                columns key,value
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2
                name default.srcbucket_mapjoin_part_2
                partition_columns ds
                serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1301691357
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcbucket_mapjoin_part_2
            name: default.srcbucket_mapjoin_part_2
        hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 
          Partition
            base file name: ds=2008-04-09
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-09
            properties:
              bucket_count 2
              bucket_field_name key
              columns key,value
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09
              name default.srcbucket_mapjoin_part_2
              partition_columns ds
              serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1301691357
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 2
                bucket_field_name key
                columns key,value
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/srcbucket_mapjoin_part_2
                name default.srcbucket_mapjoin_part_2
                partition_columns ds
                serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1301691357
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.srcbucket_mapjoin_part_2
            name: default.srcbucket_mapjoin_part_2

  Stage: Stage-5
    Conditional Operator

  Stage: Stage-4
    Move Operator
      files:
          hdfs directory: true
          source: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10002
          destination: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10000

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10000
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
                name default.bucketmapjoin_tmp_result
                numFiles 1
                numPartitions 0
                numRows 0
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 17966
                transient_lastDdlTime 1301691422
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.bucketmapjoin_tmp_result
          tmp directory: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10001

  Stage: Stage-2
    Stats-Aggr Operator
      Stats Aggregation Key Prefix: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10000/

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10002 
            File Output Operator
              compressed: false
              GlobalTableId: 0
              directory: hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10000
              NumFilesPerFileSink: 1
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    bucket_count -1
                    columns key,value1,value2
                    columns.types string:string:string
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
                    name default.bucketmapjoin_tmp_result
                    numFiles 1
                    numPartitions 0
                    numRows 0
                    serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 17966
                    transient_lastDdlTime 1301691422
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  name: default.bucketmapjoin_tmp_result
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false
      Needs Tagging: false
      Path -> Alias:
        hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10002 [hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10002]
      Path -> Partition:
        hdfs://monster01.sf.cloudera.com:17020/tmp/hive-hudson/hive_2011-04-01_13-57-41_645_9053634577540746990/-ext-10002 
          Partition
            base file name: -ext-10002
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value1,value2
              columns.types string:string:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
              name default.bucketmapjoin_tmp_result
              numFiles 1
              numPartitions 0
              numRows 0
              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 17966
              transient_lastDdlTime 1301691422
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_tmp_result
                name default.bucketmapjoin_tmp_result
                numFiles 1
                numPartitions 0
                numRows 0
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 17966
                transient_lastDdlTime 1301691422
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.bucketmapjoin_tmp_result
            name: default.bucketmapjoin_tmp_result




insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part_2 b 
on a.key=b.key


select count(1) from bucketmapjoin_tmp_result
928

insert overwrite table bucketmapjoin_hash_result_1
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
Deleted hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_hash_result_1
set hive.optimize.bucketmapjoin = false

insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part_2 b 
on a.key=b.key


select count(1) from bucketmapjoin_tmp_result
928

insert overwrite table bucketmapjoin_hash_result_2
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
Deleted hdfs://monster01.sf.cloudera.com:17020/user/hive/warehouse/bucketmapjoin_hash_result_2


select a.key-b.key, a.value1-b.value1, a.value2-b.value2
from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
on a.key = b.key
0	0	0
